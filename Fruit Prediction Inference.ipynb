{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f1f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Real-Time Fruit Freshness Detection using a Trained VGG16 Classifier\n",
    "Can predict from static image or webcam feed.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as T\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision.models import vgg16, VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16f458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class info\n",
    "CLASS_LABELS = [\"fresh apple\", \"fresh banana\", \"fresh orange\", \"rotten apple\", \"rotten banana\", \"rotten orange\"]\n",
    "FRUIT_TYPE = {0: \"Apple\", 1: \"Banana\", 2: \"Orange\", 3: \"Apple\", 4: \"Banana\", 5: \"Orange\"}\n",
    "FRUIT_STATE = {0: \"Fresh\", 1: \"Fresh\", 2: \"Fresh\", 3: \"Rotten\", 4: \"Rotten\", 5: \"Rotten\"}\n",
    "\n",
    "# Load model architecture and weights\n",
    "def load_model(path=\"fruit_model.pth\"):\n",
    "    model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "    model.classifier[6] = nn.Linear(4096, 6)\n",
    "\n",
    "    custom_model = nn.Sequential(\n",
    "        model.features,\n",
    "        model.avgpool,\n",
    "        nn.Flatten(),\n",
    "        model.classifier[0:3],\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(4096, 500),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(500, 6)\n",
    "    )\n",
    "    custom_model.load_state_dict(torch.load(path, map_location=device))\n",
    "    return custom_model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ba0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformation for inference\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4388164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from PIL or OpenCV image\n",
    "\n",
    "def predict_and_annotate(image, model, device):\n",
    "    original_h, original_w = image.shape[:2]\n",
    "    img_resized = cv2.resize(image, (224, 224))\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "    img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        class_id = output.argmax(1).item()\n",
    "\n",
    "    label = f\"{FRUIT_TYPE[class_id]} - {FRUIT_STATE[class_id]}\"\n",
    "\n",
    "    # Draw square on center of original image resolution\n",
    "    box_w, box_h = original_w // 3, original_h // 3\n",
    "    x1 = (original_w - box_w) // 2\n",
    "    y1 = (original_h - box_h) // 2\n",
    "    x2 = x1 + box_w\n",
    "    y2 = y1 + box_h\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=3)\n",
    "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f628541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from image path\n",
    "def predict_from_image(path, model, device):\n",
    "    image = cv2.imread(path)\n",
    "    annotated = predict_and_annotate(image, model, device)\n",
    "    cv2.imshow(\"Prediction\", annotated)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a15949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from webcam\n",
    "def predict_from_camera(model, device):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"Press 'q' to quit\")\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        annotated = predict_and_annotate(frame, model, device)\n",
    "        cv2.imshow(\"Webcam Prediction\", annotated)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1bd267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okeiy\\AppData\\Local\\Temp\\ipykernel_3516\\75066285.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  custom_model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "my_model = load_model(\"C:/Users/okeiy/Downloads/Nvdia Learning/fruit_model_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ca439df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "# Use either one:\n",
    "\n",
    "# predict_from_image(\"C:/Users/okeiy/Downloads/Nvdia Learning/5.jpg\", my_model, device)\n",
    "\n",
    "#  Or \n",
    "\n",
    "predict_from_camera(my_model, device)\n",
    "\n",
    "# Note: Ensure the model path is correct and the model is trained with the same architecture.\n",
    "# The webcam feed will show real-time predictions with annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f35288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
